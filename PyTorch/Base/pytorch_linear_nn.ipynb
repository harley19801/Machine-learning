{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f055cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba1c3f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c3f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img = os.getcwd() + '/../../../../images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66741a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6713d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=path_to_img, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root=path_to_img, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8e70e",
   "metadata": {},
   "source": [
    "Before computing mean and std  \n",
    "we need to change pixels range from 1..255 to 0..1  \n",
    "\n",
    "That's because during transforms first step should be `ToTensor`  \n",
    "which transform data to tensor and change the range of data to 0..1  \n",
    "So when we apply `Normalize` in next step we have another range of data  \n",
    "and can't use mean from data with range 1..255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9abf1334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.1307\n",
      "std  = 0.3081\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(train_dataset.data.float()/255)\n",
    "std = torch.std(train_dataset.data.float()/255)\n",
    "\n",
    "print(f'mean = {mean:.4f}')\n",
    "print(f'std  = {std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd13424",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transforms = transforms.Compose(\n",
    "    [  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "        transforms.Lambda(lambda x: x.view(-1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe2784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.transform = mnist_transforms\n",
    "test_dataset.transform = mnist_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cce3479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c200a8b",
   "metadata": {},
   "source": [
    "Transforms applying only when you accessing data form DataLoader.  \n",
    "Data in datset is non changed.  \n",
    "We can see it if we run the same code for computing mean and std of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5157d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.1307\n",
      "std  = 0.3081\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(train_dataset.data.float()/255)\n",
    "std = torch.std(train_dataset.data.float()/255)\n",
    "\n",
    "print(f'mean = {mean:.4f}')\n",
    "print(f'std  = {std:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d17fa",
   "metadata": {},
   "source": [
    "Data in batches is transformed and has normalized mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00bc947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.0119\n",
      "std  = 1.0103\n"
     ]
    }
   ],
   "source": [
    "# Get one batch\n",
    "data_iter = iter(train_loader)\n",
    "batch = next(data_iter)\n",
    "data, targets = batch\n",
    "print(f'mean = {data.mean():.4f}')\n",
    "print(f'std  = {data.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a88f7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader:\n",
    "            #move to cuda\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, predictions = outputs.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "524f13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e73a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 3\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0fdc562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0: 100%|███████████████████████████████| 469/469 [00:10<00:00, 45.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_loss = 0.3682, v_loss: 0.2176, t_acc = 0.8949, v_acc = 0.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1: 100%|███████████████████████████████| 469/469 [00:11<00:00, 41.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_loss = 0.1929, v_loss: 0.1581, t_acc = 0.9444, v_acc = 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2: 100%|███████████████████████████████| 469/469 [00:11<00:00, 39.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_loss = 0.1423, v_loss: 0.1404, t_acc = 0.9586, v_acc = 0.9587\n",
      "\n",
      "fin_train_acc: 0.9641, fin_test_acc: 0.9587\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader, ncols=80, desc=f'epoch: {epoch}')):\n",
    "        #move to cuda\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        #make predictions\n",
    "        outputs = model(data)\n",
    "        \n",
    "        #calculating loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        #calculate gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #change parameters with gradient * learning_rate\n",
    "        optimizer.step()\n",
    "        \n",
    "        #save loss\n",
    "        running_train_loss += loss\n",
    "        \n",
    "        #calculate and save accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += predicted.size(0)\n",
    "        correct_train += (predicted == targets).sum()\n",
    "    \n",
    "    #accumulated loss / number of batches\n",
    "    train_loss = running_train_loss / len(train_loader)\n",
    "    \n",
    "    #number of correct predictions / number of images\n",
    "    train_acc = correct_train / total_train\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            #move to cuda\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            #make predictions\n",
    "            outputs = model(data)\n",
    "            \n",
    "            #calculating loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            #save loss\n",
    "            running_val_loss += loss\n",
    "\n",
    "            #calculate and save accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += predicted.size(0)\n",
    "            correct_val += (predicted == targets).sum()\n",
    "\n",
    "    #accumulated loss / number of batches\n",
    "    val_loss = running_val_loss / len(test_loader)\n",
    "    \n",
    "    #number of correct predictions / number of images\n",
    "    val_acc = correct_val / total_val\n",
    "        \n",
    "    print(f't_loss = {train_loss:.4f}, v_loss: {val_loss:.4f}, t_acc = {train_acc:.4f}, v_acc = {val_acc:.4f}')\n",
    "\n",
    "# checking final accuracy\n",
    "train_acc = check_accuracy(train_loader, model).item()\n",
    "test_acc = check_accuracy(test_loader, model).item()\n",
    "print(f'\\nfin_train_acc: {train_acc:.4f}, fin_test_acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83413a0",
   "metadata": {},
   "source": [
    "```\n",
    " 5 epochs -lin 50                         - 96.09  \n",
    " 5 epochs -lin 100                        - 97.06  \n",
    " 5 epochs -lin 50 + lin50                 - 96.17  \n",
    " 5 epochs -lin 100 + lin100               - 97.10  \n",
    " 5 epochs -lin 100 + lin100 + lin100      - 97.41  \n",
    " 5 epochs -lin 150 + lin150 + lin150      - 97.60  \n",
    " 5 epochs -lin 250 + lin250 + lin250      - 97.81  \n",
    " 5 epochs -lin 250 + lin50 + lin250       - 97.60  \n",
    " 5 epochs -lin 250 + lin40 + lin250       - 97.34  \n",
    " 5 epochs -lin 250 + lin500 + lin250      - 97.38  \n",
    " 5 epochs -lin 784 + lin784 + lin784      - 97.62  \n",
    " 5 epochs -lin 1784 + lin1784 + lin1784   - 98.14  \n",
    "25 epochs -lin 50                         - 97.23  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120fad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
