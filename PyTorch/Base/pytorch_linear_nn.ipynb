{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harley19801/Machine-learning/blob/main/PyTorch/Base/pytorch_linear_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f055cc7f",
      "metadata": {
        "id": "f055cc7f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ba1c3f8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba1c3f8a",
        "outputId": "480ca081-3406-440b-f3d4-aa75a206e1ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "66741a5e",
      "metadata": {
        "id": "66741a5e"
      },
      "outputs": [],
      "source": [
        "input_size = 784\n",
        "num_classes = 10\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b9c3f85a",
      "metadata": {
        "id": "b9c3f85a"
      },
      "outputs": [],
      "source": [
        "path_to_img = os.getcwd() + '/../../../../images'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid error messages from unavailable site http://yann.lecun.com/exdb/mnist/"
      ],
      "metadata": {
        "id": "ieQL9SvqtCVn"
      },
      "id": "ieQL9SvqtCVn"
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.MNIST.resources = [\n",
        "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
        "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
        "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
        "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
        "        ]"
      ],
      "metadata": {
        "id": "nWcUu9jTs5EZ"
      },
      "id": "nWcUu9jTs5EZ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6713d724",
      "metadata": {
        "id": "6713d724"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(root=path_to_img, train=True, download=True)\n",
        "test_dataset = datasets.MNIST(root=path_to_img, train=False, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd8e70e",
      "metadata": {
        "id": "5bd8e70e"
      },
      "source": [
        "Before computing mean and std  \n",
        "we need to change pixels range from 1..255 to 0..1  \n",
        "\n",
        "That's because during transforms first step should be `ToTensor`  \n",
        "which transform data to tensor and change the range of data to 0..1  \n",
        "So when we apply `Normalize` in next step we have another range of data  \n",
        "and can't use mean from data with range 1..255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9abf1334",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9abf1334",
        "outputId": "b9034d5a-1017-4f23-f65a-49c9db30ac55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean = 0.1307\n",
            "std  = 0.3081\n"
          ]
        }
      ],
      "source": [
        "mean = torch.mean(train_dataset.data.float()/255)\n",
        "std = torch.std(train_dataset.data.float()/255)\n",
        "\n",
        "print(f'mean = {mean:.4f}')\n",
        "print(f'std  = {std:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 transformation convert PIL image into tensor format and change pixels range from 1..255 to 0..1  \n",
        "2 transformation normalize data and change mean to 0 and std to 1\n",
        "3 transforamtion change shape of image from 28*28 to 784  \n",
        "We had tensor shape 60000, 28, 28 and transform it to 60000, 784"
      ],
      "metadata": {
        "id": "m4qLCKbdwHC_"
      },
      "id": "m4qLCKbdwHC_"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7bd13424",
      "metadata": {
        "id": "7bd13424"
      },
      "outputs": [],
      "source": [
        "mnist_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "        transforms.Lambda(lambda x: x.view(-1)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms applying only when you accessing data form DataLoader.  "
      ],
      "metadata": {
        "id": "PIgbncLAt5NI"
      },
      "id": "PIgbncLAt5NI"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "bfe2784a",
      "metadata": {
        "id": "bfe2784a"
      },
      "outputs": [],
      "source": [
        "train_dataset.transform = mnist_transforms\n",
        "test_dataset.transform = mnist_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "cce3479b",
      "metadata": {
        "id": "cce3479b"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c200a8b",
      "metadata": {
        "id": "3c200a8b"
      },
      "source": [
        "At this step data in datset is not changed.  \n",
        "Actually it will not be changed even after accessing batch from the DataLoader  \n",
        "We can see it if we run the same code for computing mean and std of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5157d7ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5157d7ad",
        "outputId": "fedb830e-84c5-45f8-d4ac-5ddb18a53b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean = 0.1307\n",
            "std  = 0.3081\n"
          ]
        }
      ],
      "source": [
        "mean = torch.mean(train_dataset.data.float()/255)\n",
        "std = torch.std(train_dataset.data.float()/255)\n",
        "\n",
        "print(f'mean = {mean:.4f}')\n",
        "print(f'std  = {std:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "510d17fa",
      "metadata": {
        "id": "510d17fa"
      },
      "source": [
        "Data in dataset is not changed and has mean 0.130 and std 0.308  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "00bc947f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00bc947f",
        "outputId": "5f4da610-a5cc-4a6c-f32c-6c305aacf1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean = 0.0186\n",
            "std  = 1.0192\n"
          ]
        }
      ],
      "source": [
        "# Get one batch\n",
        "data_iter = iter(train_loader)\n",
        "batch = next(data_iter)\n",
        "data, targets = batch\n",
        "print(f'mean = {data.mean():.4f}')\n",
        "print(f'std  = {data.std():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data in batches is transformed and has normalized mean 0.003 and std 1.001"
      ],
      "metadata": {
        "id": "lENSfbOxv71A"
      },
      "id": "lENSfbOxv71A"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a88f7d3b",
      "metadata": {
        "id": "a88f7d3b"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in loader:\n",
        "            #move to cuda/cpu\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            _, predictions = outputs.max(1)\n",
        "            num_correct += (predictions == targets).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    return num_correct / num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "524f13e6",
      "metadata": {
        "id": "524f13e6"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9e73a15e",
      "metadata": {
        "id": "9e73a15e"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "num_epochs = 3\n",
        "\n",
        "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a0fdc562",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0fdc562",
        "outputId": "4eb46fcc-fe70-41a0-91a8-faf864141dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 0: 100%|███████████████████████████████| 469/469 [00:17<00:00, 27.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_loss = 0.3711, v_loss: 0.2095, t_acc = 0.8957, v_acc = 0.9388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 1: 100%|███████████████████████████████| 469/469 [00:16<00:00, 27.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_loss = 0.1864, v_loss: 0.1550, t_acc = 0.9462, v_acc = 0.9531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 2: 100%|███████████████████████████████| 469/469 [00:17<00:00, 27.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_loss = 0.1377, v_loss: 0.1260, t_acc = 0.9599, v_acc = 0.9617\n",
            "\n",
            "fin_train_acc: 0.9687, fin_test_acc: 0.9617\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader, ncols=80, desc=f'epoch: {epoch}')):\n",
        "        #move to cuda/cpu\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        #make predictions\n",
        "        outputs = model(data)\n",
        "\n",
        "        #calculating loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        #calculate gradient\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        #change parameters with gradient * learning_rate\n",
        "        optimizer.step()\n",
        "\n",
        "        #save loss\n",
        "        running_train_loss += loss\n",
        "\n",
        "        #calculate and save accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        total_train += predicted.size(0)\n",
        "        correct_train += (predicted == targets).sum()\n",
        "\n",
        "    #accumulated loss / number of batches\n",
        "    train_loss = running_train_loss / len(train_loader)\n",
        "\n",
        "    #number of correct predictions / number of images\n",
        "    train_acc = correct_train / total_train\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            #move to cuda/cpu\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            #make predictions\n",
        "            outputs = model(data)\n",
        "\n",
        "            #calculating loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            #save loss\n",
        "            running_val_loss += loss\n",
        "\n",
        "            #calculate and save accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_val += predicted.size(0)\n",
        "            correct_val += (predicted == targets).sum()\n",
        "\n",
        "    #accumulated loss / number of batches\n",
        "    val_loss = running_val_loss / len(test_loader)\n",
        "\n",
        "    #number of correct predictions / number of images\n",
        "    val_acc = correct_val / total_val\n",
        "\n",
        "    print(f't_loss = {train_loss:.4f}, v_loss: {val_loss:.4f}, t_acc = {train_acc:.4f}, v_acc = {val_acc:.4f}')\n",
        "\n",
        "# checking final accuracy\n",
        "train_acc = check_accuracy(train_loader, model).item()\n",
        "test_acc = check_accuracy(test_loader, model).item()\n",
        "print(f'\\nfin_train_acc: {train_acc:.4f}, fin_test_acc: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f83413a0",
      "metadata": {
        "id": "f83413a0"
      },
      "source": [
        "Result from other linear models with different architectures/number of epochs\n",
        "```\n",
        " 5 epochs -lin 50                         - 96.09  \n",
        " 5 epochs -lin 100                        - 97.06  \n",
        " 5 epochs -lin 50 + lin50                 - 96.17  \n",
        " 5 epochs -lin 100 + lin100               - 97.10  \n",
        " 5 epochs -lin 100 + lin100 + lin100      - 97.41  \n",
        " 5 epochs -lin 150 + lin150 + lin150      - 97.60  \n",
        " 5 epochs -lin 250 + lin250 + lin250      - 97.81  \n",
        " 5 epochs -lin 250 + lin50 + lin250       - 97.60  \n",
        " 5 epochs -lin 250 + lin40 + lin250       - 97.34  \n",
        " 5 epochs -lin 250 + lin500 + lin250      - 97.38  \n",
        " 5 epochs -lin 784 + lin784 + lin784      - 97.62  \n",
        " 5 epochs -lin 1784 + lin1784 + lin1784   - 98.14  \n",
        "25 epochs -lin 50                         - 97.23  \n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:fastai]",
      "language": "python",
      "name": "conda-env-fastai-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}